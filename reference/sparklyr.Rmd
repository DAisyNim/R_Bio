---
title: "sparklyr"
output:
  word_document: default
  html_notebook: default
---

### sparklyr — R interface for Apache Spark 의 설치와 사용법

- CentOS 6.7
- 사전 준비

```{bash  eval=FALSE}
sudo yum -y install libcurl-devel
```


```{r   eval=FALSE}  
install.packages("sparklyr" , repos = 'http://cran.nexr.com') 
```

```{r}
library(sparklyr)
# spark_install(version = "1.6.2")

if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
  Sys.setenv(SPARK_HOME = "/home/goodmit/spark")
}
sc <- spark_connect(master = "local")
```

#### Reading Data

```{r eval=FALSE} 
install.packages("dplyr", repos = "http://cran.nexr.com" )
install.packages("nycflights13", repos = "http://cran.nexr.com" )
install.packages("Lahman" , repos = "http://cran.nexr.com" )
```


```{r}
library(dplyr)
library(nycflights13)

iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
```

```{r}
src_tbls(sc)
```

#### Using dplyr
```{r}
# filter by departure delay
flights_tbl %>% filter(dep_delay == 2)
```

```{r}
delay <- flights_tbl %>% 
  group_by(tailnum) %>%
  summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
  filter(count > 20, dist < 2000, !is.na(delay)) %>%
  collect()
```

```{r eval=FALSE}
install.packages('ggplot2', repos = 'http://cran.nexr.com')
```


```{r}
# plot delays
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
  geom_point(aes(size = count), alpha = 1/2) +
  geom_smooth() +
  scale_size_area(max_size = 2)
```


### spark + R 의 장점
- Spark에서 병렬처리가 가능하도록 구현한 머신러닝 LIB을 사용하고, 결과를 R의 시각화 패키지로 보여줌.

#### K-Means Clustering

```{r}
kmeans_model <- iris_tbl %>%
  select(Petal_Width, Petal_Length) %>%
  ml_kmeans(centers = 3)

# print our model fit
print(kmeans_model)
```

```{r}
predicted <- sdf_predict(kmeans_model, iris_tbl) %>%  collect

table(predicted$Species, predicted$prediction)
```

```{r}
# plot cluster membership
sdf_predict(kmeans_model) %>%
  collect() %>%
  ggplot(aes(Petal_Length, Petal_Width)) +
  geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
             size = 2, alpha = 0.5) + 
  geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
             col = scales::muted(c("red", "green", "blue")),
             pch = 'x', size = 12) +
  scale_color_discrete(name = "Predicted Cluster",
                       labels = paste("Cluster", 1:3)) +
  labs(
    x = "Petal Length",
    y = "Petal Width",
    title = "K-Means Clustering",
    subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
  )
```

